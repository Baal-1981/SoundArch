# SoundArch v2.0 ğŸ§

> **A professional-grade Android hearing assistant app with native DSP, ultra-low latency, Bluetooth routing, and embedded ML.**

<p align="center">
  <img src="https://img.shields.io/badge/Latency-%3C10ms-green"/>
  <img src="https://img.shields.io/badge/Audio-DSP%20Real--Time-blue"/>
  <img src="https://img.shields.io/badge/ML-TFLite%20on--device-orange"/>
  <img src="https://img.shields.io/badge/UI-Jetpack%20Compose-purple"/>
</p>

---

## ğŸ‡¬ğŸ‡§ ENGLISH VERSION â€” TECHNICAL OVERVIEW

### ğŸ¯ Purpose

SoundArch is designed for:

* Assisting hearing-impaired users with **adaptive, low-latency audio correction**
* **Realtime signal processing**: Equalization, Compression, Psychoacoustic tuning
* **Smart routing**: Bluetooth beamforming and mic-array directionality (planned)
* **Edge ML**: personalized gain profiles with `.tflite` inference

ğŸ”§ It targets professional use cases (medical, industrial, defense) with latency under 10ms and modular design.

ğŸ“ **Hardware targeted**: Pixel 5, S23 FE, Galaxy Buds 3 Pro, Jabra Evolve 2 â€” with support for mic arrays and custom audio HAL in future.

---

### ğŸ“ Full Project Structure

```
SoundArch/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/main/java/com/soundarch/
â”‚   â”‚   â”œâ”€â”€ MainActivity.kt                  # Entry point + permissions
â”‚   â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”‚   â”œâ”€â”€ screens/                    # HomeScreen, EqualizerScreen, etc.
â”‚   â”‚   â”‚   â”œâ”€â”€ components/                 # LatencyIndicator, AudioVisualizer
â”‚   â”‚   â”‚   â””â”€â”€ navigation/                 # NavGraph.kt
â”‚   â”‚   â”œâ”€â”€ viewmodels/                     # AudioViewModel, etc.
â”‚   â”‚   â”œâ”€â”€ data/                           # Repositories, models
â”‚   â”‚   â”œâ”€â”€ utils/                          # Helpers, Bluetooth manager
â”‚   â”‚   â””â”€â”€ native/NativeAudioEngine.kt     # JNI wrapper to C++
â”‚   â”œâ”€â”€ src/main/cpp/
â”‚   â”‚   â”œâ”€â”€ native-lib.cpp                  # JNI Entry point
â”‚   â”‚   â”œâ”€â”€ audio/                          # OboeEngine, Buffer, Latency
â”‚   â”‚   â”œâ”€â”€ dsp/                            # Equalizer, Compressor, Limiter
â”‚   â”‚   â”œâ”€â”€ ml/                             # TFLiteEngine, VAD, PsychoAcoustic
â”‚   â”‚   â””â”€â”€ utils/                          # Logger, RingBuffer
â”œâ”€â”€ ml-training/                            # Python: train + export .tflite
â”œâ”€â”€ build.gradle.kts                        # Kotlin DSL build config
â””â”€â”€ README.md                               # This file
```

---

### ğŸ§  Audio Engine Breakdown (C++)

#### `OboeEngine.h/.cpp`

* `initialize(int sampleRate)` â€“ Builds input and output Oboe streams at given sample rate, configures low-latency exclusive mode.
* `start()` â€“ Starts both audio streams and sets `isRunning_ = true`
* `stop()` â€“ Stops both streams safely
* `release()` â€“ Releases streams and buffers
* `onAudioReady()` â€“ Oboe callback: reads input, calls processing chain, writes to output stream
* `setAudioCallback()` â€“ Assigns DSP processing callback
* `getCurrentLatencyMs()` â€“ Returns current estimated latency (output frame position - input frame position)

#### `LatencyMonitor.h/.cpp`

* Tracks input/output timestamps to compute round-trip latency over time
* Uses `atomic<double>` to avoid locks

#### `AudioBuffer.h`

* Defines a lock-free circular buffer (single-producer single-consumer) for safe transfer between threads

#### `BluetoothRouter.cpp`

* Manages detection and routing to Bluetooth output devices (planned)

---

### ğŸ›ï¸ DSP Modules

#### `Equalizer.h/.cpp`

* 10-band Biquad filter bank
* `setBandGain(band, gainDb)` â€“ Updates coefficients live
* `process(float)` â€“ Sequentially applies each filter
* `reset()` â€“ Resets all filtersâ€™ states

#### `Compressor.h/.cpp`

* `setThreshold()`, `setRatio()`, `setAttack()`, `setRelease()` â€“ Sets compression parameters
* `process(float)` â€“ Applies RMS envelope tracking and dynamic gain reduction

---

### ğŸ¤– ML C++ Engine

#### `TFLiteEngine.cpp`

* Loads `.tflite` models from asset path
* Sets up TensorFlow Lite interpreter in C++
* `runInference(input, output)` â€“ Runs prediction using allocated tensors

#### `PsychoAcoustic.cpp`, `VAD.cpp`

* Wrap logic for psychoacoustic filtering and speech detection (WIP)

---

### ğŸ”— JNI Bridge (native-lib.cpp)

* Exposes `initialize`, `start`, `stop`, `release`, `setEqBands(float[])` to Kotlin
* All methods use batch processing and avoid local ref leaks

```cpp
JNIEXPORT jboolean JNICALL initialize(JNIEnv*, jobject, jint sampleRate);
JNIEXPORT jboolean JNICALL start(JNIEnv*, jobject);
JNIEXPORT void JNICALL stop(JNIEnv*, jobject);
JNIEXPORT void JNICALL release(JNIEnv*, jobject);
JNIEXPORT void JNICALL setEqBands(JNIEnv*, jobject, jfloatArray);
JNIEXPORT jdouble JNICALL getCurrentLatency(JNIEnv*, jobject);
```

---

### ğŸ–¼ï¸ Kotlin UI (Jetpack Compose)

#### `MainActivity.kt`

* Entry point, requests permissions
* Hosts navigation and content setup

#### `ui/screens/`

* `HomeScreen.kt` â†’ Displays latency, EQ access
* `EqualizerScreen.kt` â†’ 10-band EQ sliders
* `BluetoothScreen.kt`, `AudioTestScreen.kt` â†’ placeholders

#### `components/`

* `LatencyIndicator` â€“ visual ring showing ms delay
* `AudioVisualizer` â€“ simple waveform based on RMS
* `MetricsCard` â€“ summary of runtime audio stats

#### `viewmodels/AudioViewModel.kt`

* Maintains state using `StateFlow`
* Triggers native methods (start, stop, update EQ)

```kotlin
val latency: StateFlow<Double>
val rmsLevel: StateFlow<Float>
val eqProfile: StateFlow<FloatArray>
```

---

### ğŸ“Š Runtime Metrics

* `latency` â€“ JNI call
* `rmsLevel` â€“ computed per block
* `eqProfile` â€“ pushed to C++

---

### ğŸ§ª Testing

* `AudioViewModelTest.kt` â€“ Compose lifecycle + toggle
* C++ planned: GoogleTest for DSP correctness
* JNI: instrumentation via AndroidTest (future)

---

### ğŸ“… Roadmap

* [x] EQ + Compressor
* [ ] Limiter + Psycho/VAD
* [ ] Adaptive ML tuning
* [ ] Bluetooth routing + beamforming

---

### ğŸ™ Credits

Developed by **Baal-1981**, in collaboration with GPT-4o, targeting audio DSP for hearing sciences, embedded ML and real-time mobile apps.

---

## ğŸ‡«ğŸ‡· VERSION FRANÃ‡AISE â€” SPÃ‰CIFICATION TECHNIQUE

[Traduction complÃ¨te identique Ã  venir dans le bloc suivant pour assurer la continuitÃ©, complÃ¨te et aussi dÃ©taillÃ©e.]
